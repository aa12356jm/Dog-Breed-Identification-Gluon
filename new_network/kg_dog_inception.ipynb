{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解压数据集\n",
    "训练数据集train.zip和测试数据集test.zip都是压缩格式，下载后它们的路径可以如下：\n",
    "\n",
    "../data/kaggle_dog/train.zip\n",
    "../data/kaggle_dog/test.zip\n",
    "../data/kaggle_dog/labels.csv.zip\n",
    "为了使网页编译快一点，我们在git repo里仅仅存放小数据样本（’train_valid_test_tiny.zip’）。执行以下代码会从git repo里解压生成小数据样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 如果训练下载的Kaggle的完整数据集，把demo改为False。\n",
    "demo = False\n",
    "data_dir = './'\n",
    "\n",
    "if demo:\n",
    "    zipfiles= ['train_valid_test_tiny.zip']\n",
    "else:\n",
    "    zipfiles= ['train.zip', 'test.zip', 'labels.csv.zip']\n",
    "\n",
    "import zipfile\n",
    "for fin in zipfiles:\n",
    "    with zipfile.ZipFile(data_dir + '/' + fin, 'r') as zin:\n",
    "        zin.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T08:49:57.522240Z",
     "start_time": "2018-01-12T08:49:57.518246Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo = False\n",
    "data_dir = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整理数据集\n",
    "对于Kaggle的完整数据集，我们需要定义下面的reorg_dog_data函数来整理一下。整理后，同一类狗的图片将出现在在同一个文件夹下，便于Gluon稍后读取。\n",
    "\n",
    "函数中的参数如data_dir、train_dir和test_dir对应上述数据存放路径及原始训练和测试的图片集文件夹名称。参数label_file为训练数据标签的文件名称。参数input_dir是整理后数据集文件夹名称。参数valid_ratio是验证集中每类狗的数量占原始训练集中数量最少一类的狗的数量（66）的比重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T08:50:06.392557Z",
     "start_time": "2018-01-12T08:50:06.341195Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "\n",
    "def reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir,\n",
    "                   valid_ratio):\n",
    "    # 读取训练数据标签。\n",
    "    with open(os.path.join(data_dir, label_file), 'r') as f:\n",
    "        # 跳过文件头行（栏名称）。\n",
    "        lines = f.readlines()[1:]\n",
    "        tokens = [l.rstrip().split(',') for l in lines]\n",
    "        idx_label = dict(((idx, label) for idx, label in tokens))\n",
    "    labels = set(idx_label.values())\n",
    "\n",
    "    num_train = len(os.listdir(os.path.join(data_dir, train_dir)))\n",
    "    # 训练集中数量最少一类的狗的数量。\n",
    "    min_num_train_per_label = (\n",
    "        Counter(idx_label.values()).most_common()[:-2:-1][0][1])\n",
    "    # 验证集中每类狗的数量。\n",
    "    num_valid_per_label = math.floor(min_num_train_per_label * valid_ratio)\n",
    "    label_count = dict()\n",
    "\n",
    "    def mkdir_if_not_exist(path):\n",
    "        if not os.path.exists(os.path.join(*path)):\n",
    "            os.makedirs(os.path.join(*path))\n",
    "\n",
    "    # 整理训练和验证集。\n",
    "    for train_file in os.listdir(os.path.join(data_dir, train_dir)):\n",
    "        idx = train_file.split('.')[0]\n",
    "        label = idx_label[idx]\n",
    "        mkdir_if_not_exist([data_dir, input_dir, 'train_valid', label])\n",
    "        shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                    os.path.join(data_dir, input_dir, 'train_valid', label))\n",
    "        if label not in label_count or label_count[label] < num_valid_per_label:\n",
    "            mkdir_if_not_exist([data_dir, input_dir, 'valid', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                        os.path.join(data_dir, input_dir, 'valid', label))\n",
    "            label_count[label] = label_count.get(label, 0) + 1\n",
    "        else:\n",
    "            mkdir_if_not_exist([data_dir, input_dir, 'train', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                        os.path.join(data_dir, input_dir, 'train', label))\n",
    "\n",
    "    # 整理测试集。\n",
    "    mkdir_if_not_exist([data_dir, input_dir, 'test', 'unknown'])\n",
    "    for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n",
    "        shutil.copy(os.path.join(data_dir, test_dir, test_file),\n",
    "                    os.path.join(data_dir, input_dir, 'test', 'unknown'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次强调，为了使网页编译快一点，我们在这里仅仅使用小数据样本。相应地，我们仅将批量大小设为2。实际训练和测试时应使用Kaggle的完整数据集并调用reorg_dog_data函数整理便于Gluon读取的格式。由于数据集较大，批量大小batch_size大小可设为一个较大的整数，例如128。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T08:50:19.788334Z",
     "start_time": "2018-01-12T08:50:19.782348Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if demo:\n",
    "    # 注意：此处使用小数据集为便于网页编译。\n",
    "    input_dir = 'train_valid_test_tiny'\n",
    "    # 注意：此处相应使用小批量。对Kaggle的完整数据集可设较大的整数，例如128。\n",
    "    batch_size = 2\n",
    "else:\n",
    "    label_file = 'labels.csv'\n",
    "    train_dir = 'train'\n",
    "    test_dir = 'test'\n",
    "    input_dir = 'train_valid_test'\n",
    "    batch_size = 64\n",
    "    valid_ratio = 0.1\n",
    "    #reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir,\n",
    "                 #  valid_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Gluon读取整理后的数据集\n",
    "为避免过拟合，我们在这里使用image.CreateAugmenter来增广数据集。例如我们设rand_mirror=True即可随机对每张图片做镜面反转。以下我们列举了该函数里的所有参数，这些参数都是可以调的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T08:50:35.511572Z",
     "start_time": "2018-01-12T08:50:31.477936Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon.data import vision\n",
    "import numpy as np\n",
    "\n",
    "def transform_train(data, label):\n",
    "    im = image.imresize(data.astype('float32') / 255, 363, 363)\n",
    "    #im = image.imresize(data.astype('float32') / 255, 400, 400)\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 363, 363), resize=0, \n",
    "                        rand_crop=False, rand_resize=False, rand_mirror=True,\n",
    "                        mean=np.array([0.485, 0.456, 0.406]), std=np.array([0.229, 0.224, 0.225]), \n",
    "                        brightness=0, contrast=0, \n",
    "                        saturation=0, hue=0, \n",
    "                        pca_noise=0, rand_gray=0, inter_method=2)\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    # 将数据格式从\"高*宽*通道\"改为\"通道*高*宽\"。\n",
    "    im = nd.transpose(im, (2,0,1))\n",
    "    return (im, nd.array([label]).asscalar().astype('float32'))\n",
    "\n",
    "def transform_test(data, label):\n",
    "    im = image.imresize(data.astype('float32') / 255, 363, 363)\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 363, 363),\n",
    "                        mean=np.array([0.485, 0.456, 0.406]),\n",
    "                        std=np.array([0.229, 0.224, 0.225]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2,0,1))\n",
    "    return (im, nd.array([label]).asscalar().astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们可以使用Gluon中的ImageFolderDataset类来读取整理后的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T08:51:24.814442Z",
     "start_time": "2018-01-12T08:51:06.429490Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_str = data_dir + '/' + input_dir + '/'\n",
    "\n",
    "# 读取原始图像文件。flag=1说明输入图像有三个通道（彩色）。\n",
    "train_ds = vision.ImageFolderDataset(input_str + 'train', flag=1,\n",
    "                                     transform=transform_train)\n",
    "valid_ds = vision.ImageFolderDataset(input_str + 'valid', flag=1,\n",
    "                                     transform=transform_test)\n",
    "train_valid_ds = vision.ImageFolderDataset(input_str + 'train_valid',\n",
    "                                           flag=1, transform=transform_train)\n",
    "test_ds = vision.ImageFolderDataset(input_str + 'test', flag=1,\n",
    "                                     transform=transform_test)\n",
    "\n",
    "loader = gluon.data.DataLoader\n",
    "train_data = loader(train_ds, batch_size, shuffle=True, last_batch='keep')\n",
    "valid_data = loader(valid_ds, batch_size, shuffle=True, last_batch='keep')\n",
    "train_valid_data = loader(train_valid_ds, batch_size, shuffle=True,\n",
    "                          last_batch='keep')\n",
    "test_data = loader(test_ds, batch_size, shuffle=False, last_batch='keep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T08:52:39.295211Z",
     "start_time": "2018-01-12T08:52:39.277189Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "from mxnet import init\n",
    "#from mxnet.gluon.data import vision\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "def get_features(ctx):\n",
    "    inception = vision.inception_v3(pretrained=True,ctx=ctx)\n",
    "    return inception.features\n",
    "\n",
    "\n",
    "def get_output(ctx,ParamsName=None):\n",
    "    net = nn.HybridSequential()\n",
    "    with net.name_scope():\n",
    "        net.add(nn.Dropout(.2))\n",
    "        net.add(nn.Dense(256, activation=\"relu\"))\n",
    "        net.add(nn.Dropout(.6))\n",
    "        net.add(nn.Dense(120))\n",
    "    if ParamsName is not None:\n",
    "        #net.collect_params().load(ParamsName,ctx)\n",
    "        net.load_params(ParamsName,ctx)\n",
    "    else:\n",
    "        net.initialize(init = init.Xavier(),ctx=ctx)\n",
    "    return net\n",
    "\n",
    "def get_net(ParamsName,ctx):\n",
    "    output = get_output(ctx,ParamsName)\n",
    "    features = get_features(ctx)\n",
    "    net = nn.HybridSequential()\n",
    "    with net.name_scope():\n",
    "        net.add(features)\n",
    "        net.add(output)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T08:52:43.220844Z",
     "start_time": "2018-01-12T08:52:41.652177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridSequential(\n",
      "  (0): HybridSequential(\n",
      "    (0): Conv2D(3 -> 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=32)\n",
      "    (2): Activation(relu)\n",
      "  )\n",
      "  (1): HybridSequential(\n",
      "    (0): Conv2D(32 -> 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=32)\n",
      "    (2): Activation(relu)\n",
      "  )\n",
      "  (2): HybridSequential(\n",
      "    (0): Conv2D(32 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "    (2): Activation(relu)\n",
      "  )\n",
      "  (3): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  (4): HybridSequential(\n",
      "    (0): Conv2D(64 -> 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=80)\n",
      "    (2): Activation(relu)\n",
      "  )\n",
      "  (5): HybridSequential(\n",
      "    (0): Conv2D(80 -> 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "    (2): Activation(relu)\n",
      "  )\n",
      "  (6): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  (7): HybridConcurrent(\n",
      "    (0): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(192 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(192 -> 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=48)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(48 -> 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(192 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(64 -> 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=96)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(96 -> 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=96)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridSequential(\n",
      "      (0): AvgPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(192 -> 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=32)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (8): HybridConcurrent(\n",
      "    (0): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(256 -> 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=48)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(48 -> 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(64 -> 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=96)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(96 -> 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=96)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridSequential(\n",
      "      (0): AvgPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (9): HybridConcurrent(\n",
      "    (0): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(288 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(288 -> 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=48)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(48 -> 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(288 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(64 -> 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=96)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(96 -> 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=96)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridSequential(\n",
      "      (0): AvgPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(288 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (10): HybridConcurrent(\n",
      "    (0): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(288 -> 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(288 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=64)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(64 -> 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=96)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(96 -> 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=96)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (11): HybridConcurrent(\n",
      "    (0): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=128)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(128 -> 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=128)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(128 -> 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=128)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(128 -> 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=128)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(128 -> 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=128)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (3): HybridSequential(\n",
      "        (0): Conv2D(128 -> 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=128)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (4): HybridSequential(\n",
      "        (0): Conv2D(128 -> 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridSequential(\n",
      "      (0): AvgPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (12): HybridConcurrent(\n",
      "    (0): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=160)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(160 -> 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=160)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(160 -> 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=160)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(160 -> 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=160)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(160 -> 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=160)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (3): HybridSequential(\n",
      "        (0): Conv2D(160 -> 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=160)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (4): HybridSequential(\n",
      "        (0): Conv2D(160 -> 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridSequential(\n",
      "      (0): AvgPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (13): HybridConcurrent(\n",
      "    (0): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=160)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(160 -> 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=160)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(160 -> 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=160)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(160 -> 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=160)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(160 -> 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=160)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (3): HybridSequential(\n",
      "        (0): Conv2D(160 -> 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=160)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (4): HybridSequential(\n",
      "        (0): Conv2D(160 -> 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridSequential(\n",
      "      (0): AvgPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (14): HybridConcurrent(\n",
      "    (0): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(192 -> 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(192 -> 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(192 -> 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(192 -> 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (3): HybridSequential(\n",
      "        (0): Conv2D(192 -> 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (4): HybridSequential(\n",
      "        (0): Conv2D(192 -> 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridSequential(\n",
      "      (0): AvgPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (15): HybridConcurrent(\n",
      "    (0): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(192 -> 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=320)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(192 -> 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv2D(192 -> 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (3): HybridSequential(\n",
      "        (0): Conv2D(192 -> 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (16): HybridConcurrent(\n",
      "    (0): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(1280 -> 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=320)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): HybridSequential(\n",
      "          (0): Conv2D(1280 -> 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "      )\n",
      "      (1): HybridConcurrent(\n",
      "        (0): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(384 -> 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "            (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "            (2): Activation(relu)\n",
      "          )\n",
      "        )\n",
      "        (1): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(384 -> 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "            (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "            (2): Activation(relu)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): HybridSequential(\n",
      "          (0): Conv2D(1280 -> 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=448)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "        (1): HybridSequential(\n",
      "          (0): Conv2D(448 -> 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "      )\n",
      "      (1): HybridConcurrent(\n",
      "        (0): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(384 -> 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "            (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "            (2): Activation(relu)\n",
      "          )\n",
      "        )\n",
      "        (1): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(384 -> 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "            (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "            (2): Activation(relu)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): HybridSequential(\n",
      "      (0): AvgPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(1280 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (17): HybridConcurrent(\n",
      "    (0): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv2D(2048 -> 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=320)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): HybridSequential(\n",
      "          (0): Conv2D(2048 -> 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "      )\n",
      "      (1): HybridConcurrent(\n",
      "        (0): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(384 -> 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "            (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "            (2): Activation(relu)\n",
      "          )\n",
      "        )\n",
      "        (1): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(384 -> 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "            (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "            (2): Activation(relu)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): HybridSequential(\n",
      "        (0): HybridSequential(\n",
      "          (0): Conv2D(2048 -> 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=448)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "        (1): HybridSequential(\n",
      "          (0): Conv2D(448 -> 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "      )\n",
      "      (1): HybridConcurrent(\n",
      "        (0): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(384 -> 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "            (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "            (2): Activation(relu)\n",
      "          )\n",
      "        )\n",
      "        (1): HybridSequential(\n",
      "          (0): HybridSequential(\n",
      "            (0): Conv2D(384 -> 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "            (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=384)\n",
      "            (2): Activation(relu)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): HybridSequential(\n",
      "      (0): AvgPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv2D(2048 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm(momentum=0.9, axis=1, eps=0.001, fix_gamma=False, in_channels=192)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (18): AvgPool2D(size=(8, 8), stride=(8, 8), padding=(0, 0), ceil_mode=False)\n",
      "  (19): Dropout(p = 0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "net2=get_features(mx.gpu())\n",
    "print(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:04:20.665486Z",
     "start_time": "2018-01-12T08:52:49.012709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取特征 train_inception_v3.nd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 149/149 [05:54<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存特征 train_inception_v3.nd\n",
      "提取特征 valid_inception_v3.nd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:15<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存特征 valid_inception_v3.nd\n",
      "提取特征 input_inception_v3.nd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [05:14<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存特征 input_inception_v3.nd\n"
     ]
    }
   ],
   "source": [
    "from mxnet import nd\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "net = get_features(mx.gpu())\n",
    "net.hybridize()\n",
    "\n",
    "def SaveNd(data,net,name):\n",
    "    x =[]\n",
    "    y =[]\n",
    "    print('提取特征 %s' % name)\n",
    "    for fear,label in tqdm(data):\n",
    "        x.append(net(fear.as_in_context(mx.gpu())).as_in_context(mx.cpu()))\n",
    "        y.append(label)\n",
    "    x = nd.concat(*x,dim=0)\n",
    "    y = nd.concat(*y,dim=0)\n",
    "    print('保存特征 %s' % name)\n",
    "    nd.save(name,[x,y])\n",
    "\n",
    "\n",
    "SaveNd(train_data,net,'train_inception_v3.nd')\n",
    "SaveNd(valid_data,net,'valid_inception_v3.nd')\n",
    "SaveNd(train_valid_data,net,'input_inception_v3.nd')\n",
    "# SaveNd(test_data,net,'test_resnet152_v1.nd')\n",
    "ids = ids = sorted(os.listdir(os.path.join(data_dir, input_dir, 'test/unknown')))\n",
    "synsets = train_valid_ds.synsets\n",
    "f = open('ids_synsets','wb')\n",
    "pickle.dump([ids,synsets],f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:06:38.689252Z",
     "start_time": "2018-01-12T09:05:57.175640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train loss: 4.431166, Valid loss 3.645063, Time 00:00:00, lr 0.0001\n",
      "Epoch 1. Train loss: 3.178143, Valid loss 2.044522, Time 00:00:00, lr 0.0001\n",
      "Epoch 2. Train loss: 2.058037, Valid loss 1.113622, Time 00:00:00, lr 0.0001\n",
      "Epoch 3. Train loss: 1.427413, Valid loss 0.740518, Time 00:00:00, lr 0.0001\n",
      "Epoch 4. Train loss: 1.087030, Valid loss 0.548652, Time 00:00:00, lr 0.0001\n",
      "Epoch 5. Train loss: 0.901971, Valid loss 0.461604, Time 00:00:00, lr 0.0001\n",
      "Epoch 6. Train loss: 0.768393, Valid loss 0.413115, Time 00:00:00, lr 0.0001\n",
      "Epoch 7. Train loss: 0.706201, Valid loss 0.378153, Time 00:00:00, lr 0.0001\n",
      "Epoch 8. Train loss: 0.641921, Valid loss 0.339545, Time 00:00:00, lr 0.0001\n",
      "Epoch 9. Train loss: 0.577190, Valid loss 0.351832, Time 00:00:00, lr 0.0001\n",
      "Epoch 10. Train loss: 0.540982, Valid loss 0.319038, Time 00:00:00, lr 0.0001\n",
      "Epoch 11. Train loss: 0.520884, Valid loss 0.289822, Time 00:00:00, lr 0.0001\n",
      "Epoch 12. Train loss: 0.496402, Valid loss 0.309584, Time 00:00:00, lr 0.0001\n",
      "Epoch 13. Train loss: 0.472012, Valid loss 0.274096, Time 00:00:00, lr 0.0001\n",
      "Epoch 14. Train loss: 0.446212, Valid loss 0.277563, Time 00:00:00, lr 0.0001\n",
      "Epoch 15. Train loss: 0.427514, Valid loss 0.307589, Time 00:00:00, lr 0.0001\n",
      "Epoch 16. Train loss: 0.394388, Valid loss 0.265329, Time 00:00:00, lr 0.0001\n",
      "Epoch 17. Train loss: 0.395101, Valid loss 0.267353, Time 00:00:00, lr 0.0001\n",
      "Epoch 18. Train loss: 0.372642, Valid loss 0.270487, Time 00:00:00, lr 0.0001\n",
      "Epoch 19. Train loss: 0.369005, Valid loss 0.251512, Time 00:00:00, lr 0.0001\n",
      "Epoch 20. Train loss: 0.358278, Valid loss 0.266977, Time 00:00:00, lr 0.0001\n",
      "Epoch 21. Train loss: 0.345808, Valid loss 0.260761, Time 00:00:00, lr 0.0001\n",
      "Epoch 22. Train loss: 0.341951, Valid loss 0.268285, Time 00:00:00, lr 0.0001\n",
      "Epoch 23. Train loss: 0.327870, Valid loss 0.254245, Time 00:00:00, lr 0.0001\n",
      "Epoch 24. Train loss: 0.330435, Valid loss 0.248130, Time 00:00:00, lr 0.0001\n",
      "Epoch 25. Train loss: 0.316201, Valid loss 0.249675, Time 00:00:00, lr 0.0001\n",
      "Epoch 26. Train loss: 0.293017, Valid loss 0.261241, Time 00:00:00, lr 0.0001\n",
      "Epoch 27. Train loss: 0.302514, Valid loss 0.258247, Time 00:00:00, lr 0.0001\n",
      "Epoch 28. Train loss: 0.287050, Valid loss 0.259209, Time 00:00:00, lr 0.0001\n",
      "Epoch 29. Train loss: 0.280983, Valid loss 0.247796, Time 00:00:00, lr 0.0001\n",
      "Epoch 30. Train loss: 0.276279, Valid loss 0.252853, Time 00:00:00, lr 0.0001\n",
      "Epoch 31. Train loss: 0.266085, Valid loss 0.265276, Time 00:00:00, lr 0.0001\n",
      "Epoch 32. Train loss: 0.271523, Valid loss 0.246973, Time 00:00:00, lr 0.0001\n",
      "Epoch 33. Train loss: 0.266942, Valid loss 0.270131, Time 00:00:00, lr 0.0001\n",
      "Epoch 34. Train loss: 0.251717, Valid loss 0.242926, Time 00:00:00, lr 0.0001\n",
      "Epoch 35. Train loss: 0.249322, Valid loss 0.249966, Time 00:00:00, lr 0.0001\n",
      "Epoch 36. Train loss: 0.244386, Valid loss 0.235855, Time 00:00:00, lr 0.0001\n",
      "Epoch 37. Train loss: 0.244838, Valid loss 0.246606, Time 00:00:00, lr 0.0001\n",
      "Epoch 38. Train loss: 0.228928, Valid loss 0.243856, Time 00:00:00, lr 0.0001\n",
      "Epoch 39. Train loss: 0.231893, Valid loss 0.243475, Time 00:00:00, lr 0.0001\n",
      "Epoch 40. Train loss: 0.224320, Valid loss 0.253750, Time 00:00:00, lr 0.0001\n",
      "Epoch 41. Train loss: 0.231296, Valid loss 0.247641, Time 00:00:00, lr 0.0001\n",
      "Epoch 42. Train loss: 0.220830, Valid loss 0.282499, Time 00:00:00, lr 0.0001\n",
      "Epoch 43. Train loss: 0.213346, Valid loss 0.277832, Time 00:00:00, lr 0.0001\n",
      "Epoch 44. Train loss: 0.212546, Valid loss 0.246271, Time 00:00:00, lr 0.0001\n",
      "Epoch 45. Train loss: 0.208253, Valid loss 0.241634, Time 00:00:00, lr 0.0001\n",
      "Epoch 46. Train loss: 0.208224, Valid loss 0.255584, Time 00:00:00, lr 0.0001\n",
      "Epoch 47. Train loss: 0.205327, Valid loss 0.254628, Time 00:00:00, lr 0.0001\n",
      "Epoch 48. Train loss: 0.200557, Valid loss 0.254712, Time 00:00:00, lr 0.0001\n",
      "Epoch 49. Train loss: 0.203389, Valid loss 0.246526, Time 00:00:00, lr 0.0001\n",
      "Epoch 50. Train loss: 0.192861, Valid loss 0.264442, Time 00:00:00, lr 0.0001\n",
      "Epoch 51. Train loss: 0.194888, Valid loss 0.241174, Time 00:00:00, lr 0.0001\n",
      "Epoch 52. Train loss: 0.194146, Valid loss 0.249859, Time 00:00:00, lr 0.0001\n",
      "Epoch 53. Train loss: 0.187204, Valid loss 0.241032, Time 00:00:00, lr 0.0001\n",
      "Epoch 54. Train loss: 0.191069, Valid loss 0.250146, Time 00:00:00, lr 0.0001\n",
      "Epoch 55. Train loss: 0.177668, Valid loss 0.254734, Time 00:00:00, lr 0.0001\n",
      "Epoch 56. Train loss: 0.180915, Valid loss 0.242855, Time 00:00:00, lr 0.0001\n",
      "Epoch 57. Train loss: 0.175300, Valid loss 0.244189, Time 00:00:00, lr 0.0001\n",
      "Epoch 58. Train loss: 0.175917, Valid loss 0.250579, Time 00:00:00, lr 0.0001\n",
      "Epoch 59. Train loss: 0.170368, Valid loss 0.286188, Time 00:00:00, lr 0.0001\n",
      "Epoch 60. Train loss: 0.171958, Valid loss 0.262972, Time 00:00:00, lr 0.0001\n",
      "Epoch 61. Train loss: 0.166494, Valid loss 0.251368, Time 00:00:00, lr 0.0001\n",
      "Epoch 62. Train loss: 0.159771, Valid loss 0.253360, Time 00:00:00, lr 0.0001\n",
      "Epoch 63. Train loss: 0.158806, Valid loss 0.261852, Time 00:00:00, lr 0.0001\n",
      "Epoch 64. Train loss: 0.154433, Valid loss 0.262102, Time 00:00:00, lr 0.0001\n",
      "Epoch 65. Train loss: 0.158961, Valid loss 0.249128, Time 00:00:00, lr 0.0001\n",
      "Epoch 66. Train loss: 0.152762, Valid loss 0.251234, Time 00:00:00, lr 0.0001\n",
      "Epoch 67. Train loss: 0.152062, Valid loss 0.246676, Time 00:00:00, lr 0.0001\n",
      "Epoch 68. Train loss: 0.152403, Valid loss 0.300694, Time 00:00:00, lr 0.0001\n",
      "Epoch 69. Train loss: 0.155517, Valid loss 0.262929, Time 00:00:00, lr 0.0001\n",
      "Epoch 70. Train loss: 0.146627, Valid loss 0.256865, Time 00:00:00, lr 0.0001\n",
      "Epoch 71. Train loss: 0.146864, Valid loss 0.248358, Time 00:00:00, lr 0.0001\n",
      "Epoch 72. Train loss: 0.145994, Valid loss 0.246455, Time 00:00:00, lr 0.0001\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon.data import vision\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import pickle\n",
    "\n",
    "train_nd = nd.load('train_inception_v3.nd')\n",
    "\n",
    "valid_nd = nd.load('valid_inception_v3.nd')\n",
    "\n",
    "input_nd = nd.load('input_inception_v3.nd')\n",
    "\n",
    "f = open('ids_synsets','rb')\n",
    "ids_synsets = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "num_epochs = 73\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-5\n",
    "lr_period = 40\n",
    "lr_decay = 0.1\n",
    "pngname='1'\n",
    "modelparams='1'\n",
    "\n",
    "train_data_d = gluon.data.DataLoader(gluon.data.ArrayDataset(train_nd[0],train_nd[1]), batch_size=batch_size,shuffle=True)\n",
    "valid_data_d = gluon.data.DataLoader(gluon.data.ArrayDataset(valid_nd[0],valid_nd[1]), batch_size=batch_size,shuffle=True)\n",
    "input_data_d = gluon.data.DataLoader(gluon.data.ArrayDataset(input_nd[0],input_nd[1]), batch_size=batch_size,shuffle=True)\n",
    "\n",
    "\n",
    "def get_loss(data, net, ctx):\n",
    "    loss = 0.0\n",
    "    for feas, label in data:\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(feas.as_in_context(ctx))\n",
    "        cross_entropy = softmax_cross_entropy(output, label)\n",
    "        loss += nd.mean(cross_entropy).asscalar()\n",
    "    return loss / len(data)\n",
    "\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "def train(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_period, \n",
    "          lr_decay):\n",
    "    trainer = gluon.Trainer(\n",
    "        net.collect_params(), 'adam', {'learning_rate': lr, 'wd': wd})\n",
    "    #trainer = gluon.Trainer(\n",
    "     #   net.collect_params(), 'sgd', {'learning_rate': lr, 'momentum': 0.9,\n",
    "      #                                'wd': wd})\n",
    "    train_loss = []\n",
    "    if valid_data is not None:\n",
    "        test_loss = []\n",
    "    \n",
    "    prev_time = datetime.datetime.now()\n",
    "    for epoch in range(num_epochs):\n",
    "        _loss = 0.\n",
    "        #if epoch > 0 and epoch % lr_period == 0:\n",
    "         #   trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        for data, label in train_data:\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output = net(data.as_in_context(ctx))\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size)\n",
    "            _loss += nd.mean(loss).asscalar()\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        __loss = _loss/len(train_data)\n",
    "        train_loss.append(__loss)\n",
    "        \n",
    "        if valid_data is not None:  \n",
    "            valid_loss = get_loss(valid_data, net, ctx)\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, Valid loss %f, \"\n",
    "                         % (epoch,__loss , valid_loss))\n",
    "            test_loss.append(valid_loss)\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, \"\n",
    "                         % (epoch, __loss))\n",
    "            \n",
    "        prev_time = cur_time\n",
    "        print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))\n",
    "        \n",
    "\n",
    "    plt.plot(train_loss, 'r')\n",
    "    if valid_data is not None: \n",
    "        plt.plot(test_loss, 'g')\n",
    "    plt.legend(['Train_Loss', 'Test_Loss'], loc=2)\n",
    "\n",
    "\n",
    "    plt.savefig(pngname, dpi=1000)\n",
    "    #net.collect_params().save(modelparams)\n",
    "    savefilename = \"./inception_v3.params\"\n",
    "    net.save_params(savefilename)\n",
    "\n",
    "ctx = mx.gpu()\n",
    "net = get_output(ctx)\n",
    "net.hybridize()\n",
    "\n",
    "#train(net, input_data_d,None, num_epochs, learning_rate, weight_decay, \n",
    " #     ctx, lr_period, lr_decay)\n",
    "train(net, train_data_d,valid_data_d, num_epochs, learning_rate, weight_decay, \n",
    "      ctx, lr_period, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:14:34.611159Z",
     "start_time": "2018-01-12T09:08:10.641003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 162/162 [06:22<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "#from mxnet.gluon.data import vision\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#from model import get_net\n",
    "\n",
    "data_dir = './'\n",
    "test_dir = 'test'\n",
    "input_dir = 'train_valid_test'\n",
    "valid_dir = 'valid'\n",
    "input_str = data_dir + '/' + input_dir + '/'\n",
    "\n",
    "netparams =\"./inception_v3.params\"\n",
    "csvname = 'p2_2.csv'\n",
    "ids_synsets_name = 'ids_synsets'\n",
    "\n",
    "f = open(ids_synsets_name,'rb')\n",
    "ids_synsets = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "def SaveTest(test_data,net,ctx,name,ids,synsets):\n",
    "    outputs = []\n",
    "    for data, label in tqdm(test_data):\n",
    "        output = nd.softmax(net(data.as_in_context(ctx)))\n",
    "        outputs.extend(output.asnumpy())\n",
    "    with open(name, 'w') as f:\n",
    "        f.write('id,' + ','.join(synsets) + '\\n')\n",
    "        for i, output in zip(ids, outputs):\n",
    "            f.write(i.split('.')[0] + ',' + ','.join(\n",
    "                [str(num) for num in output]) + '\\n')\n",
    "\n",
    "net = get_net(netparams,mx.gpu())\n",
    "net.hybridize()\n",
    "\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "#print(get_loss(valid_data,net,mx.gpu()))\n",
    "\n",
    "SaveTest(test_data,net,mx.gpu(),csvname,ids_synsets[0],ids_synsets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
