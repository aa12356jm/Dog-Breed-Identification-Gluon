1，此文件夹中是使用单模型来训练数据，是多模型融合的简化版本
使用单模型的目的是为了在C++中部署，因为多个模型融合的话，每个模型要求的输入图像大小不一样，在c++中只能指定一个输入大小；
所以这里使用单模型，但是发现单模型使用export导出的模型也不能在c++中使用，具体原因不清楚，待查询
（本文件夹中的文件finetuning.py也是使用gluon来训练数据，可以正常训练且export导出模型和网络文件，并且可以在c++中正常使用，
待后续查原因）

2，这里是使用迁移学习的方式来训练网络，即冻结预训练模型的feature层，手动写output层，并且只训练output层



迁移学习说明：
迁移学习有两种，微调（fine-tuning）和冻结（freezing）。
（1）fine-tuning会对预训练层也进行权重更新，这时候需要设置两个学习率，较小的用于对预训练层进行更新，较大的用于对分类层进行更新；

（2）freezing保持预训练层的权重不变，只训练分类层。

通常在自己的数据集不大的时候，用 freezing，如果自己的数据集足够大且自己的数据集与预训练数据集有较大差异时，用 fine-tuning。

通常 fine-tuning 的效果优于freezing，不过 freezing 可以快速得到一个不错的结果，主要适合小数据集且数据集差异不大的情况。

在建立模型的时候，注意看 API 里的参数，比如 pretrained=True 这样的